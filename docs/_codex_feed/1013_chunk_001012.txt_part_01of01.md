# File: chunk_001012.txt (part 1 of 1)
```
“check-the-box” activity into a meaningful defense mechanism. AI is also poised to revolutionize compliance itself. Instead of manual reviews of data-flow diagrams or lengthy interviews to verify controls, AI could continuously validate documentation and flag changes in real time. That ensures merchants and service providers maintain PCI DSS throughout the year—not just during a QSA assessment. Finally, payment security operations are already benefiting. We hear already that Security Operations Centers (SOC) integrate AI for root-cause analysis now to uncover subtle anomalies—the proverbial “needles in the haystack”—with far greater accuracy. In effect, AI becomes an always-on analyst, augmenting human staff with tireless pattern recognition and other intelligence features. What potential risks should organizations consider as AI becomes more integrated into payment security? The first risk is over-reliance on AI decisioning without human oversight. Generative AI is inherently probabilistic; unlike deterministic static software, it may produce unexpected outputs. In payments, we’ve already seen chatbot rollouts fail because customer creativity exposed edge cases that deviated from company policy. The risk escalates with agentic AI use cases—where autonomous AI agents act on behalf of users. Too often, organizations secure the employee’s ID but neglect to account for what the AI agent itself can access or execute. This creates over-privileged agents with little governance, undermining PCI DSS controls for least privilege and access management. Authentication is also evolving rapidly under AI pressure. Biometric data, once thought nearly impossible to spoof, can now be mimicked. While AI can sometimes detect these deepfake or “bio phishing” attempts today, it is unrealistic to assume that defensive AI will always stay ahead of malicious AI. Ultimately, if organizations fail to document agent privileges, validate AI outputs, and maintain oversight, they risk eroding PCI DSS’s foundational requirements for access control, auditability, and secure authentication. What advice would you provide for an organization just starting their journey into using AI? Start with the basics and ask the “why” question. Too often, I hear financial institutions being told to “make this an AI process” without clarity on the value. The right entry point is identifying use cases that clearly enhance security, efficiency, or compliance outcomes (although adding “AI” to any budget request seems to help prioritize the item). From there, pilot wisely. Choose a manageable scope, give it adequate duration, and designate internal champions responsible for monitoring AI behavior and outcomes. Treat it as you would a new vendor or system within your PCI DSS environment: prove it at small scale before scaling widely. Next, test rigorously. Each new AI model or parameter update should be checked against a baseline set of questions to ensure it hasn’t altered results unexpectedly. Unlike traditional patches that can be applied automatically, AI updates may subtly change behavior in ways that matter deeply to your business and compliance. Finally, codify everything in an AI policy. About two-thirds of companies now report AI as a risk in their annual assessments. Embedding governance of AI into your existing information security policy—already required under PCI DSS Requirement 12—ensures alignment across the organization and prepares you for external scrutiny. What AI trend (not limited to payments) are you most excited about? I’m excited by the automation of repetitive, documentation-heavy tasks. For merchants and service providers, PCI DSS evidence collection has always been resource intensive. AI now promises to streamline control mapping, generate compliance narratives, and maintain document libraries dynamically. This makes ongoing assessment more efficient and less disruptive. On a more technical level, I’m encouraged by the rapid adoption of Model Context Protocol (MCP) and Agent-to-Agent (A2A) protocols. These universally accepted protocols act as translators between AI agents and applications (or other agents), standardizing how systems communicate. For organizations, that means reduced vendor lock-in, improved interoperability, and a clearer governance model for AI adoption. Standardization is often an unsung hero in security. Just as PCI DSS itself provides a common foundation for payment security, these AI communication protocols can create consistency that accelerates adoption while reducing systemic risk for everyone, wherever they may be on their AI journey. Interested in learning more? Register now to see Troy Leach speak at the 2025 Europe Community Meeting where he will deliver his AI-themed presentation, It’s Not You, It’s Us – Strategy for Building a Shared Security Responsibility Model with your Service Providers.
```

